# -*- coding: utf-8 -*-
"""Codergirl_Julie_Week_12.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/0B_CClw1DrQTPQm1VUFZFZWk0ZkhiZWJmU2FlTng5dS1NQnZB
"""

from PIL import Image
import numpy as np
from keras.datasets import mnist
from keras.models import Sequential
from keras.layers.core import Dense, Dropout, Activation
from keras.optimizers import RMSprop
from keras.utils import np_utils
from keras.utils import to_categorical
import matplotlib.pyplot as plt
from sklearn.model_selection import train_test_split

np.random.seed(1671)  # for reproducibility

# network and training
NB_EPOCH = 20
BATCH_SIZE = 128 # Size of 
VERBOSE = 1
NB_CLASSES = 10   # number of outputs = number of digits
OPTIMIZER = RMSprop() # optimizer 
N_HIDDEN = 128 # number of hidden units
VALIDATION_SPLIT=0.2 # how much TRAIN is reserved for VALIDATION
DROPOUT = 0.3 # Used for regularization
RESHAPED = 784 # Number of features to be used (28X28 pixels)

#read in MNIST pictures
(x_train, y_train), (x_test, y_test) = mnist.load_data()

#since the model expects a single feature vector of size 784 #convert from (28,28) to 784 
x_train = x_train.reshape(60000,784).astype('float32')
x_test = x_test.reshape(10000,784).astype('float32')

np.amax(x_train)

#normalize x_train and x_test vectors
x_train = x_train/255
x_test = x_test/255
print(x_train.shape[0], 'train samples')
print(x_test.shape[0], 'test samples')

#return maximum value of array
np.amax(x_train)

y_train_encoded = to_categorical(y_train)
y_test_encoded = to_categorical(y_test)

print(y_train_encoded[59999])

#check to make sure one-hot encoding command accurately executed
print(y_train[59999])

# One-hot vector encoding
print(y_train[3])

# Original class vector
print(y_train_encoded[3])

x_train.shape[1]

# NB_CLASSES = 10   # number of outputs = number of digits
# N_HIDDEN = 128 # number of hidden units
# DROPOUT = 0.3 # Used for regularization
# RESHAPED = 784 # Number of features to be used 
'''Problem 5 : Build Neural Network using Keras model functions
Look up Sequential, Dense, Activation
Print model summary'''

model = Sequential()
model.add(Dropout(0.3, input_shape=(x_train.shape[1],)))
model.add(Dense(N_HIDDEN))
model.add(Activation('sigmoid'))
model.add(Dense(y_train_encoded.shape[1]))
model.add(Activation('softmax'))

#model.add(Dense(10, activation='sigmoid'))

model.summary()

#Problem 6 : compile the model you built from Problem 5
#Use appropriate loss function, optimizer, and performance metric

model.compile(optimizer='adam',
              loss='categorical_crossentropy',
              metrics=['accuracy'])

#split into test and validation
#training validation split using sckitlearn library
X_train, X_val, Y_train, Y_val = train_test_split(x_train, y_train_encoded, test_size=0.2, random_state=1)

X_train.shape

#Problem 7: Fit your model with appropriate batch size, number of epochs, verbosity, and validation split
#Save model fit to a new variable named history

history = model.fit(X_train , Y_train,
                epochs=NB_EPOCH,
                batch_size=BATCH_SIZE,
                validation_data=(X_val, Y_val))

#Evaluate Test Accuracy
#Problem 8 : Score your model using Keras functions
score = model.evaluate(x_test, y_test_encoded, verbose=0)
print(score)

print("\nTest score:", score[0])
print('Test accuracy:', score[1])

#Evaluating Accuracy Over Epochs
#Problem 9: Plot accuracy as a function of epochs

plt.plot(history.history['acc'])
plt.plot(history.history['val_acc'])
plt.title('Model accuracy')
plt.ylabel('Accuracy')
plt.xlabel('Epoch')
plt.legend(['Train', 'Test'], loc='upper left')
plt.show()

#Evaluating Loss Function Over Epochs
#Problem 10: Plot loss function as a function of epochs
## summarize history for loss

plt.plot(history.history['loss'])
plt.plot(history.history['val_loss'])
plt.title('Model loss')
plt.ylabel('Loss')
plt.xlabel('Epoch')
plt.legend(['Train', 'Test'], loc='upper left')
plt.show()



index = 5

#x_test[0].shape
lul = np.reshape(x_test[index], (1, 784))

bla = model.predict(lul)

bla = np.reshape(bla, (10, 784))

img = Image.fromarray(bla, 'L')

y_test[index]

value = 0
result = 0
for i in range(0,len(bla)):
    if(value < bla[i]):
        value = bla[i]
        result = i
print(result)

def minimum(a, n): 
  
    # inbuilt function to find the position of minimum  
    minpos = a.index(min(a)) 
      
    # inbuilt function to find the position of maximum  
    maxpos = a.index(max(a))  
      
    # printing the position  
    print( "The maximum is at position", maxpos + 1)  
    print( "The minimum is at position", minpos + 1)

